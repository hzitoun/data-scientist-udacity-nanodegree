{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "A probabilistic algorithm which is based on playing with the concept of conditional probability. It is easy to implement and very fast to train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building an email filter\n",
    "We are going to use sklearn's [MultinomialNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html) which implements the naive Bayes algorithm for multinomially distributed data, and is one of the two classic naive Bayes variants used in text classification (where the data are typically represented as word vector counts, although tf-idf vectors are also known to work well in practice). Hence, MultinomialNB is suitable for classification with discrete features (e.g., word counts for text classification)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From 12a1mailbot1@web.de  Thu Aug 22 13:17:22 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From ilug-admin@linux.ie  Thu Aug 22 13:27:39 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From sabrina@mx3.1premio.com  Thu Aug 22 14:44...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From wsup@playful.com  Thu Aug 22 16:17:00 200...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From social-admin@linux.ie  Thu Aug 22 16:37:3...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   X  y\n",
       "0  From 12a1mailbot1@web.de  Thu Aug 22 13:17:22 ...  1\n",
       "1  From ilug-admin@linux.ie  Thu Aug 22 13:27:39 ...  1\n",
       "2  From sabrina@mx3.1premio.com  Thu Aug 22 14:44...  1\n",
       "3  From wsup@playful.com  Thu Aug 22 16:17:00 200...  1\n",
       "4  From social-admin@linux.ie  Thu Aug 22 16:37:3...  1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import swifter\n",
    "import os\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "def load_files(path, isSpam):\n",
    "    for file_name in os.listdir(path):\n",
    "        content = read_email(os.path.join(path, file_name))\n",
    "        X.append(content)\n",
    "        y.append(isSpam)\n",
    "        \n",
    "def read_email(file_name):\n",
    "    try:\n",
    "        with open(file_name, 'r', encoding='latin1') as file:\n",
    "            return file.read()\n",
    "    except IOError:\n",
    "        print(\"can't open file\", file_name)\n",
    "        return \"\"\n",
    "\n",
    "spam_path = \"./datasets/emails/spam/\"\n",
    "ham_path = \"./datasets/emails/ham/\"\n",
    "\n",
    "load_files(spam_path, 1)\n",
    "load_files(ham_path, 0)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'X' : X,\n",
    "    'y' : y\n",
    "});\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to convert each email into a vector of features.\n",
    "\n",
    "1. Tokenize email's content using [NLTK's world_tokenize](https://www.nltk.org/api/nltk.tokenize.html#module-nltk.tokenize)\n",
    "1. Stem each word to remove morphological affixes from it, leaving only the word stem using [NLTK's PorterStemmer](http://www.nltk.org/howto/stem.html)\n",
    "2. Compute count of words (tokens) in each email using the sklearn's [count vectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "# uncomment if you want to check fo newer version\n",
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "\n",
    "def tokenize_and_stem_email(email_body, stemmer):\n",
    "    email_contents = preprocess_email(email_body)\n",
    "    result = ''\n",
    "    for token in word_tokenize(email_contents):\n",
    "        # Remove any non alphanumeric characters\n",
    "        word = regexprep(token.strip(), '[^a-zA-Z0-9]', '')\n",
    "\n",
    "        # Stem the word\n",
    "        word = stemmer.stem(word)\n",
    "        \n",
    "        result+= ' ' + word\n",
    "    \n",
    "    return result\n",
    "\n",
    "def regexprep(contents, regex, replace_value):\n",
    "    return re.sub(regex, replace_value, contents)\n",
    "\n",
    "def preprocess_email(email_body):\n",
    "    \n",
    "    email_contents = email_body.lower()\n",
    "\n",
    "    # Strip all HTML\n",
    "    email_contents = regexprep(email_contents, r'<[^<>]+>', ' ')\n",
    "\n",
    "    # Handle Numbers\n",
    "    email_contents = regexprep(email_contents, r'[0-9]+', 'number')\n",
    "\n",
    "    # Handle URLS\n",
    "    email_contents = regexprep(email_contents, r'(http|https)://[^\\s]*', 'httpaddr')\n",
    "\n",
    "    # Handle Email Addresses\n",
    "    email_contents = regexprep(email_contents, r'[^\\s]+@[^\\s]+', 'emailaddr')\n",
    "\n",
    "    # Handle $ sign\n",
    "    email_contents = regexprep(email_contents, r'[$]+', 'dollar')\n",
    "\n",
    "    # get rid of any punctuation\n",
    "    email_contents = regexprep(email_contents, r'[^\\w\\s]', '')\n",
    "\n",
    "    # remove \\n\n",
    "    email_contents = regexprep(email_contents, r'\\n', '')\n",
    "    \n",
    "    return email_contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performance issue**\n",
    "\n",
    "Applying a function without parallelising would consume too much time. We'll use [swifter](https://github.com/jmcarpenter2/swifter) to parallelise the processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing e-mails...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pandas Apply: 100%|████████████████████████████████████████████████████████████████| 2500/2500 [01:10<00:00, 35.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "print('processing e-mails...')\n",
    "stemmer = PorterStemmer()\n",
    "df['X'] = df['X'].swifter.apply(lambda email_body: tokenize_and_stem_email(email_body, stemmer))\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>from emailaddr thu aug number numbernumbernum...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>from emailaddr thu aug number numbernumbernum...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>from emailaddr thu aug number numbernumbernum...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>from emailaddr thu aug number numbernumbernum...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>from emailaddr thu aug number numbernumbernum...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   X  y\n",
       "0   from emailaddr thu aug number numbernumbernum...  1\n",
       "1   from emailaddr thu aug number numbernumbernum...  1\n",
       "2   from emailaddr thu aug number numbernumbernum...  1\n",
       "3   from emailaddr thu aug number numbernumbernum...  1\n",
       "4   from emailaddr thu aug number numbernumbernum...  1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "countVectorizer = CountVectorizer()\n",
    "counts = countVectorizer.fit_transform(df['X'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifierNB = MultinomialNB().fit(counts, df['y'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0] [[0.30411967 0.69588033]\n",
      " [0.97048709 0.02951291]]\n"
     ]
    }
   ],
   "source": [
    "samples = ['you want 100000 $??! Get it now here for free http://fishing.com', \"Hello, where are we going ?\"]\n",
    "samples_counts = countVectorizer.transform([tokenize_and_stem_email(sample, stemmer) for sample in samples])\n",
    "predictions = classifierNB.predict(samples_counts)\n",
    "print(predictions, classifierNB.predict_proba(samples_counts))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
